{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sklearn: IMDB Sentiment with TF_IDF and Stemming\"\n",
    "\n",
    "- title: \"Sklearn: IMDB Sentiment with TF_IDF and Stemming\"\n",
    "- toc: true\n",
    "- badges: False\n",
    "- comments: true\n",
    "- author: Sam Treacy\n",
    "- categories: [sklearn, pandas, gridsearch, stemming, stopwords, sentiment, nlp, classification, python]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn NLP TF-IDF Sentiment Stemming GridSearch - IMDB Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DATA/IMDB Dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].str.lower()\n",
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    cleaned = ''.join(char for char in text if char not in ('?', '!', '-','_','.',\n",
    "                                                            '@','#',':',';','\"',',',\"'\",')','(') )\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production  the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece  the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life  the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].str.replace('<br /><br />',' ').str.replace('<br>', ' ')\n",
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/samtreacy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords =nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Add some extra stopwords\n",
    "stopwords.extend(['well', 'use']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'well', 'use']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    cleaned = ' '.join(char for char in text.split(' ') if char not in stopwords)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wonderful little production  filming technique unassuming oldtimebbc fashion gives comforting sometimes discomforting sense realism entire piece  actors extremely chosen michael sheen got polari voices pat truly see seamless editing guided references williams diary entries worth watching terrificly written performed piece masterful production one great masters comedy life  realism really comes home little things fantasy guard rather traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwells murals decorating every surface terribly done'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(remove_stopwords)\n",
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stemmer.stem('programers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    combined = []\n",
    "    split_text = text.split()\n",
    "    for word in split_text:\n",
    "        stemmedword = porter_stemmer.stem(word)\n",
    "        combined.append(stemmedword)\n",
    "        \n",
    "    combined = ' '.join(combined)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'success die hard sequel surpris realli 1990 glut die hard movi cash wrong guy wrong place wrong time concept cliffhang die hard mountain time rescu sli stop mom shoot stallon career cliffhang one big nitpick dream especi expert mountain climb basejump aviat facial express act skill full excus dismiss film one overblown pile junk stallon even manag get outact hors howev forget nonsens actual lovabl undeni entertain romp deliv plenti thrill unintent plenti laugh youv got love john lithgow sneeri evil tick everi box band baddi best perman harass hapless turncoat agent rex linn traver may henri portrait serial killer michael rooker noteworthi cringeworthi perform hal insist constantli shriek pain disbelief captor man never hurt anybodi whilst sure cant realli look like ralph wait frank charact grin girl plummet death mention must go former london burn actor craig fairbrass brit bad guy come cropper whilst use hal human footbal ye cant help enjoy bit hal need good kick forget better judgement care could never happen lower act expect turn volum enjoy your look qaulen he one wear helicopt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']\n",
    "\n",
    "X = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000,), (40000,), (10000,), (10000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorise using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorize = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorize.fit_transform(X_train)\n",
    "X_test  = vectorize.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ML modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DummyClassifier(strategy='uniform')\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.50      0.50      4961\n",
      "    positive       0.50      0.50      0.50      5039\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.50      0.50      0.50     10000\n",
      " \n",
      "\n",
      "[[2474 2487]\n",
      " [2516 2523]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions),'\\n')\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89      4961\n",
      "    positive       0.88      0.91      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      " \n",
      "\n",
      "[[4324  637]\n",
      " [ 478 4561]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions),'\\n')\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1','l2'],\n",
    "              'solver':['newton-cg' 'lbfgs', 'liblinear', 'sag', 'saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] penalty=l1, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l1, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l1, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l1, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l1, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l1, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l1, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l1, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l1, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l1, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l1, solver=liblinear ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... penalty=l1, solver=liblinear, total=   0.8s\n",
      "[CV] penalty=l1, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l1, solver=liblinear, total=   1.0s\n",
      "[CV] penalty=l1, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l1, solver=liblinear, total=   0.9s\n",
      "[CV] penalty=l1, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l1, solver=liblinear, total=   0.9s\n",
      "[CV] penalty=l1, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l1, solver=liblinear, total=   0.9s\n",
      "[CV] penalty=l1, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l1, solver=sag, total=   0.0s\n",
      "[CV] penalty=l1, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l1, solver=sag, total=   0.0s\n",
      "[CV] penalty=l1, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l1, solver=sag, total=   0.0s\n",
      "[CV] penalty=l1, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l1, solver=sag, total=   0.0s\n",
      "[CV] penalty=l1, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l1, solver=sag, total=   0.0s\n",
      "[CV] penalty=l1, solver=saga .........................................\n",
      "[CV] .......................... penalty=l1, solver=saga, total=  13.9s\n",
      "[CV] penalty=l1, solver=saga .........................................\n",
      "[CV] .......................... penalty=l1, solver=saga, total=  11.1s\n",
      "[CV] penalty=l1, solver=saga .........................................\n",
      "[CV] .......................... penalty=l1, solver=saga, total=  11.4s\n",
      "[CV] penalty=l1, solver=saga .........................................\n",
      "[CV] .......................... penalty=l1, solver=saga, total=  13.1s\n",
      "[CV] penalty=l1, solver=saga .........................................\n",
      "[CV] .......................... penalty=l1, solver=saga, total=  11.4s\n",
      "[CV] penalty=l2, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l2, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l2, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l2, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l2, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l2, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l2, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l2, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l2, solver=newton-cglbfgs ...............................\n",
      "[CV] ................ penalty=l2, solver=newton-cglbfgs, total=   0.0s\n",
      "[CV] penalty=l2, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l2, solver=liblinear, total=   1.0s\n",
      "[CV] penalty=l2, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l2, solver=liblinear, total=   1.1s\n",
      "[CV] penalty=l2, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l2, solver=liblinear, total=   1.1s\n",
      "[CV] penalty=l2, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l2, solver=liblinear, total=   1.4s\n",
      "[CV] penalty=l2, solver=liblinear ....................................\n",
      "[CV] ..................... penalty=l2, solver=liblinear, total=   1.0s\n",
      "[CV] penalty=l2, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l2, solver=sag, total=   1.2s\n",
      "[CV] penalty=l2, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l2, solver=sag, total=   1.2s\n",
      "[CV] penalty=l2, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l2, solver=sag, total=   1.6s\n",
      "[CV] penalty=l2, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l2, solver=sag, total=   1.4s\n",
      "[CV] penalty=l2, solver=sag ..........................................\n",
      "[CV] ........................... penalty=l2, solver=sag, total=   1.5s\n",
      "[CV] penalty=l2, solver=saga .........................................\n",
      "[CV] .......................... penalty=l2, solver=saga, total=   1.4s\n",
      "[CV] penalty=l2, solver=saga .........................................\n",
      "[CV] .......................... penalty=l2, solver=saga, total=   1.6s\n",
      "[CV] penalty=l2, solver=saga .........................................\n",
      "[CV] .......................... penalty=l2, solver=saga, total=   1.8s\n",
      "[CV] penalty=l2, solver=saga .........................................\n",
      "[CV] .......................... penalty=l2, solver=saga, total=   1.8s\n",
      "[CV] penalty=l2, solver=saga .........................................\n",
      "[CV] .......................... penalty=l2, solver=saga, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cglbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89      4961\n",
      "    positive       0.88      0.91      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      " \n",
      "\n",
      "[[4324  637]\n",
      " [ 478 4561]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions),'\\n')\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
