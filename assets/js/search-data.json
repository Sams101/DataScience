{
  
    
        "post0": {
            "title": "02 Pandas",
            "content": "import pandas as pd . df = pd.read_csv(&#39;african_econ_crises.csv&#39;) . df.head() . case cc3 country year systemic_crisis exch_usd domestic_debt_in_default sovereign_external_debt_default gdp_weighted_default inflation_annual_cpi independence currency_crises inflation_crises banking_crisis . 0 1 | DZA | Algeria | 1870 | 1 | 0.052264 | 0 | 0 | 0.0 | 3.441456 | 0 | 0 | 0 | crisis | . 1 1 | DZA | Algeria | 1871 | 0 | 0.052798 | 0 | 0 | 0.0 | 14.149140 | 0 | 0 | 0 | no_crisis | . 2 1 | DZA | Algeria | 1872 | 0 | 0.052274 | 0 | 0 | 0.0 | -3.718593 | 0 | 0 | 0 | no_crisis | . 3 1 | DZA | Algeria | 1873 | 0 | 0.051680 | 0 | 0 | 0.0 | 11.203897 | 0 | 0 | 0 | no_crisis | . 4 1 | DZA | Algeria | 1874 | 0 | 0.051308 | 0 | 0 | 0.0 | -3.848561 | 0 | 0 | 0 | no_crisis | . df[&#39;country&#39;].nunique() . 13 . df[&#39;country&#39;].unique() . array([&#39;Algeria&#39;, &#39;Angola&#39;, &#39;Central African Republic&#39;, &#39;Ivory Coast&#39;, &#39;Egypt&#39;, &#39;Kenya&#39;, &#39;Mauritius&#39;, &#39;Morocco&#39;, &#39;Nigeria&#39;, &#39;South Africa&#39;, &#39;Tunisia&#39;, &#39;Zambia&#39;, &#39;Zimbabwe&#39;], dtype=object) . df.sort_values(&#39;inflation_annual_cpi&#39;, ascending=False).head(1) . case cc3 country year systemic_crisis exch_usd domestic_debt_in_default sovereign_external_debt_default gdp_weighted_default inflation_annual_cpi independence currency_crises inflation_crises banking_crisis . 1053 70 | ZWE | Zimbabwe | 2008 | 1 | 0.002 | 1 | 1 | 0.0 | 21989695.22 | 1 | 1 | 1 | crisis | . df[(df[&#39;country&#39;] == &#39;Kenya&#39;) &amp; (df[&#39;systemic_crisis&#39;] == 1)].sort_values(&#39;year&#39;) . case cc3 country year systemic_crisis exch_usd domestic_debt_in_default sovereign_external_debt_default gdp_weighted_default inflation_annual_cpi independence currency_crises inflation_crises banking_crisis . 475 35 | KEN | Kenya | 1985 | 1 | 16.2843 | 0 | 0 | 0.0 | 11.398 | 1 | 0 | 0 | crisis | . 476 35 | KEN | Kenya | 1986 | 1 | 16.0422 | 0 | 0 | 0.0 | 10.284 | 1 | 0 | 0 | crisis | . 477 35 | KEN | Kenya | 1987 | 1 | 16.5149 | 0 | 0 | 0.0 | 13.007 | 1 | 0 | 0 | crisis | . 478 35 | KEN | Kenya | 1988 | 1 | 18.5994 | 0 | 0 | 0.0 | 4.804 | 1 | 0 | 0 | crisis | . 479 35 | KEN | Kenya | 1989 | 1 | 21.6010 | 0 | 0 | 0.0 | 7.617 | 1 | 1 | 0 | no_crisis | . 482 35 | KEN | Kenya | 1992 | 1 | 36.2163 | 0 | 0 | 0.0 | 27.332 | 1 | 1 | 1 | crisis | . 483 35 | KEN | Kenya | 1993 | 1 | 68.1631 | 0 | 0 | 0.0 | 45.979 | 1 | 1 | 1 | crisis | . 484 35 | KEN | Kenya | 1994 | 1 | 44.8389 | 0 | 1 | 0.0 | 28.814 | 1 | 0 | 1 | crisis | . 485 35 | KEN | Kenya | 1995 | 1 | 55.9389 | 0 | 1 | 0.0 | 1.554 | 1 | 0 | 0 | crisis | . 486 35 | KEN | Kenya | 1996 | 1 | 55.0211 | 0 | 1 | 0.0 | 8.862 | 1 | 0 | 0 | no_crisis | . 487 35 | KEN | Kenya | 1997 | 1 | 62.6778 | 0 | 1 | 0.0 | 11.924 | 1 | 0 | 0 | no_crisis | . 488 35 | KEN | Kenya | 1998 | 1 | 61.9056 | 0 | 1 | 0.0 | 6.716 | 1 | 0 | 0 | no_crisis | . 489 35 | KEN | Kenya | 1999 | 1 | 72.9306 | 0 | 0 | 0.0 | 5.753 | 1 | 1 | 0 | no_crisis | . crisis = df[df[&#39;systemic_crisis&#39;]==1] crisis.groupby(&#39;country&#39;).count()[&#39;systemic_crisis&#39;] . country Algeria 4 Central African Republic 19 Egypt 6 Ivory Coast 4 Kenya 13 Morocco 2 Nigeria 10 Tunisia 5 Zambia 4 Zimbabwe 15 Name: systemic_crisis, dtype: int64 . len(df[ (df[&#39;country&#39;] == &#39;Zimbabwe&#39;) &amp; (df[&#39;sovereign_external_debt_default&#39;]==1)]) . 30 . df[df[&#39;country&#39;]==&#39;Algeria&#39;].sort_values(&#39;exch_usd&#39;, ascending=False) . case cc3 country year systemic_crisis exch_usd domestic_debt_in_default sovereign_external_debt_default gdp_weighted_default inflation_annual_cpi independence currency_crises inflation_crises banking_crisis . 84 1 | DZA | Algeria | 2014 | 0 | 87.970698 | 0 | 0 | 0.0 | 2.917000 | 1 | 0 | 0 | no_crisis | . 72 1 | DZA | Algeria | 2002 | 0 | 79.723400 | 0 | 0 | 0.0 | 1.430000 | 1 | 0 | 0 | no_crisis | . 83 1 | DZA | Algeria | 2013 | 0 | 78.148701 | 0 | 0 | 0.0 | 3.255000 | 1 | 0 | 0 | no_crisis | . 82 1 | DZA | Algeria | 2012 | 0 | 78.102500 | 0 | 0 | 0.0 | 8.916000 | 1 | 0 | 0 | no_crisis | . 71 1 | DZA | Algeria | 2001 | 0 | 77.819600 | 0 | 0 | 0.0 | 4.200000 | 1 | 0 | 0 | no_crisis | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 6 1 | DZA | Algeria | 1876 | 0 | 0.051867 | 0 | 0 | 0.0 | -1.769547 | 0 | 0 | 0 | no_crisis | . 3 1 | DZA | Algeria | 1873 | 0 | 0.051680 | 0 | 0 | 0.0 | 11.203897 | 0 | 0 | 0 | no_crisis | . 5 1 | DZA | Algeria | 1875 | 0 | 0.051546 | 0 | 0 | 0.0 | -20.924178 | 0 | 0 | 0 | no_crisis | . 4 1 | DZA | Algeria | 1874 | 0 | 0.051308 | 0 | 0 | 0.0 | -3.848561 | 0 | 0 | 0 | no_crisis | . 12 1 | DZA | Algeria | 1882 | 0 | 0.050761 | 0 | 0 | 0.0 | -12.356127 | 0 | 0 | 0 | no_crisis | . 85 rows × 14 columns . DataFrames . import pandas as pd import numpy as np . columns = [&#39;W&#39;, &#39;X&#39;, &#39;Y&#39;, &#39;Z&#39;] index = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;d&#39;,&#39;E&#39;] . np.random.seed(42) data = np.random.randint(-100, 100, (5,4)) data . array([[ 2, 79, -8, -86], [ 6, -29, 88, -80], [ 2, 21, -26, -13], [ 16, -1, 3, 51], [ 30, 49, -48, -99]]) . df = pd.DataFrame(data, index= index, columns=columns ) df . W X Y Z . A 2 | 79 | -8 | -86 | . B 6 | -29 | 88 | -80 | . C 2 | 21 | -26 | -13 | . d 16 | -1 | 3 | 51 | . E 30 | 49 | -48 | -99 | . df[&#39;W&#39;] . A 2 B 6 C 2 d 16 E 30 Name: W, dtype: int64 . df[[&#39;W&#39;, &#39;Z&#39;]] . W Z . A 2 | -86 | . B 6 | -80 | . C 2 | -13 | . d 16 | 51 | . E 30 | -99 | . type(df[&#39;W&#39;]) . pandas.core.series.Series . df[&#39;new&#39;] = df[&#39;W&#39;] + df[&#39;Y&#39;] df . W X Y Z new . A 2 | 79 | -8 | -86 | -6 | . B 6 | -29 | 88 | -80 | 94 | . C 2 | 21 | -26 | -13 | -24 | . d 16 | -1 | 3 | 51 | 19 | . E 30 | 49 | -48 | -99 | -18 | . df.drop(&#39;new&#39;, axis=1) df . W X Y Z new . A 2 | 79 | -8 | -86 | -6 | . B 6 | -29 | 88 | -80 | 94 | . C 2 | 21 | -26 | -13 | -24 | . d 16 | -1 | 3 | 51 | 19 | . E 30 | 49 | -48 | -99 | -18 | . df = df.drop(&#39;new&#39;, axis=1) df . W X Y Z . A 2 | 79 | -8 | -86 | . B 6 | -29 | 88 | -80 | . C 2 | 21 | -26 | -13 | . d 16 | -1 | 3 | 51 | . E 30 | 49 | -48 | -99 | . df.loc[&#39;A&#39;] . W 2 X 79 Y -8 Z -86 Name: A, dtype: int64 . df.loc[[&#39;A&#39;, &#39;C&#39;]] . W X Y Z . A 2 | 79 | -8 | -86 | . C 2 | 21 | -26 | -13 | . df.iloc[0] . W 2 X 79 Y -8 Z -86 Name: A, dtype: int64 . df.iloc[0:2] . W X Y Z . A 2 | 79 | -8 | -86 | . B 6 | -29 | 88 | -80 | . df.drop(&#39;C&#39;, axis=0) . W X Y Z . A 2 | 79 | -8 | -86 | . B 6 | -29 | 88 | -80 | . d 16 | -1 | 3 | 51 | . E 30 | 49 | -48 | -99 | . df.loc[[&#39;A&#39;, &#39;C&#39;], [&#39;W&#39;, &#39;Y&#39;]] . W Y . A 2 | -8 | . C 2 | -26 | . df . W X Y Z . A 2 | 79 | -8 | -86 | . B 6 | -29 | 88 | -80 | . C 2 | 21 | -26 | -13 | . d 16 | -1 | 3 | 51 | . E 30 | 49 | -48 | -99 | . df &gt; 0 . W X Y Z . A True | True | False | False | . B True | False | True | False | . C True | True | False | False | . d True | False | True | True | . E True | True | False | False | . df[df &gt; 0 ] . W X Y Z x . A 2 | 79.0 | NaN | NaN | NaN | . B 6 | NaN | 88.0 | NaN | NaN | . C 2 | 21.0 | NaN | NaN | NaN | . d 16 | NaN | 3.0 | 51.0 | NaN | . E 30 | 49.0 | NaN | NaN | NaN | . df[&#39;X&#39;] &gt; 0 . A True B False C True d False E True Name: X, dtype: bool . df[df[&#39;X&#39;] &gt; 0] . df[df[&#39;X&#39;] &gt; 0][&#39;Y&#39;] . A -8 C -26 E -48 Name: Y, dtype: int64 . df[df[&#39;X&#39;] &gt; 0 ][[&#39;X&#39;, &#39;Z&#39;]] . X Z . A 79 | -86 | . C 21 | -13 | . E 49 | -99 | . df[(df[&#39;W&#39;]&gt;0) &amp; (df[&#39;Y&#39;] &gt; 1)] . W X Y Z x . B 6 | -29 | 88 | -80 | 0 | . d 16 | -1 | 3 | 51 | 0 | . df . W X Y Z x . A 2 | 79 | -8 | -86 | 0 | . B 6 | -29 | 88 | -80 | 0 | . C 2 | 21 | -26 | -13 | 0 | . d 16 | -1 | 3 | 51 | 0 | . E 30 | 49 | -48 | -99 | 0 | . df.reset_index() . index W X Y Z x . 0 A | 2 | 79 | -8 | -86 | 0 | . 1 B | 6 | -29 | 88 | -80 | 0 | . 2 C | 2 | 21 | -26 | -13 | 0 | . 3 d | 16 | -1 | 3 | 51 | 0 | . 4 E | 30 | 49 | -48 | -99 | 0 | . newind = &#39;CA NY WY OR CO&#39;.split() newind . [&#39;CA&#39;, &#39;NY&#39;, &#39;WY&#39;, &#39;OR&#39;, &#39;CO&#39;] . df[&#39;States&#39;] = newind . df . W X Y Z x States . States . CA 2 | 79 | -8 | -86 | 0 | CA | . NY 6 | -29 | 88 | -80 | 0 | NY | . WY 2 | 21 | -26 | -13 | 0 | WY | . OR 16 | -1 | 3 | 51 | 0 | OR | . CO 30 | 49 | -48 | -99 | 0 | CO | . df.set_index(&#39;States&#39;) . W X Y Z x . States . CA 2 | 79 | -8 | -86 | 0 | . NY 6 | -29 | 88 | -80 | 0 | . WY 2 | 21 | -26 | -13 | 0 | . OR 16 | -1 | 3 | 51 | 0 | . CO 30 | 49 | -48 | -99 | 0 | . df . W X Y Z x States . States . CA 2 | 79 | -8 | -86 | 0 | CA | . NY 6 | -29 | 88 | -80 | 0 | NY | . WY 2 | 21 | -26 | -13 | 0 | WY | . OR 16 | -1 | 3 | 51 | 0 | OR | . CO 30 | 49 | -48 | -99 | 0 | CO | . df = df.set_index(&#39;States&#39;) df . W X Y Z x . States . CA 2 | 79 | -8 | -86 | 0 | . NY 6 | -29 | 88 | -80 | 0 | . WY 2 | 21 | -26 | -13 | 0 | . OR 16 | -1 | 3 | 51 | 0 | . CO 30 | 49 | -48 | -99 | 0 | . df.describe() . W X Y Z x . count 5.00000 | 5.000000 | 5.000000 | 5.000000 | 5.0 | . mean 11.20000 | 23.800000 | 1.800000 | -45.400000 | 0.0 | . std 11.96662 | 42.109381 | 51.915316 | 63.366395 | 0.0 | . min 2.00000 | -29.000000 | -48.000000 | -99.000000 | 0.0 | . 25% 2.00000 | -1.000000 | -26.000000 | -86.000000 | 0.0 | . 50% 6.00000 | 21.000000 | -8.000000 | -80.000000 | 0.0 | . 75% 16.00000 | 49.000000 | 3.000000 | -13.000000 | 0.0 | . max 30.00000 | 79.000000 | 88.000000 | 51.000000 | 0.0 | . df.dtypes . W int64 X int64 Y int64 Z int64 x int64 dtype: object . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Index: 5 entries, CA to CO Data columns (total 5 columns): # Column Non-Null Count Dtype -- -- 0 W 5 non-null int64 1 X 5 non-null int64 2 Y 5 non-null int64 3 Z 5 non-null int64 4 x 5 non-null int64 dtypes: int64(5) memory usage: 240.0+ bytes . Missing Data . import pandas as pd df = pd.DataFrame({&#39;A&#39;: [1, 2, np.nan, 4], &#39;B&#39;: [5, np.nan, np.nan, 8], &#39;C&#39;: [10, 20, 30, 40 ]}) df . A B C . 0 1.0 | 5.0 | 10 | . 1 2.0 | NaN | 20 | . 2 NaN | NaN | 30 | . 3 4.0 | 8.0 | 40 | . df.dropna() . A B C . 0 1.0 | 5.0 | 10 | . 3 4.0 | 8.0 | 40 | . df.dropna(axis=1) . C . 0 10 | . 1 20 | . 2 30 | . 3 40 | . df.dropna(thresh = 2) . A B C . 0 1.0 | 5.0 | 10 | . 1 2.0 | NaN | 20 | . 3 4.0 | 8.0 | 40 | . df.fillna(value = &#39;Fill Value&#39;) . A B C . 0 1 | 5 | 10 | . 1 2 | Fill Value | 20 | . 2 Fill Value | Fill Value | 30 | . 3 4 | 8 | 40 | . df[&#39;A&#39;].fillna(value = 0) . 0 1.0 1 2.0 2 0.0 3 4.0 Name: A, dtype: float64 . df[&#39;A&#39;].fillna(df[&#39;A&#39;].mean()) . 0 1.000000 1 2.000000 2 2.333333 3 4.000000 Name: A, dtype: float64 . df.fillna(df.mean()) . A B C . 0 1.000000 | 5.0 | 10 | . 1 2.000000 | 6.5 | 20 | . 2 2.333333 | 6.5 | 30 | . 3 4.000000 | 8.0 | 40 | . Groupby . import pandas as pd . df = pd.read_csv(&#39;Universities.csv&#39;) . df.head() . Sector University Year Completions Geography . 0 Private for-profit, 2-year | Pima Medical Institute-Las Vegas | 2016 | 591 | Nevada | . 1 Private for-profit, less-than 2-year | Healthcare Preparatory Institute | 2016 | 28 | Nevada | . 2 Private for-profit, less-than 2-year | Milan Institute-Las Vegas | 2016 | 408 | Nevada | . 3 Private for-profit, less-than 2-year | Utah College of Massage Therapy-Vegas | 2016 | 240 | Nevada | . 4 Public, 4-year or above | Western Nevada College | 2016 | 960 | Nevada | . # Step 1 simply returns a special groupby object waiting to have an aggregate method called on it! df.groupby(&#39;Year&#39;) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fa2eddab750&gt; . df.groupby(&#39;Year&#39;).mean() . Completions . Year . 2012 535.078947 | . 2013 526.150000 | . 2014 588.809524 | . 2015 597.250000 | . 2016 609.860465 | . type(df.groupby(&#39;Year&#39;).mean()) . pandas.core.frame.DataFrame . df.groupby(&#39;Year&#39;).mean().sort_index(ascending=False) . Completions . Year . 2016 609.860465 | . 2015 597.250000 | . 2014 588.809524 | . 2013 526.150000 | . 2012 535.078947 | . df.groupby(&#39;Year&#39;).mad() . Completions . Year . 2012 542.655125 | . 2013 560.455000 | . 2014 652.596372 | . 2015 661.863636 | . 2016 699.015684 | . df.groupby(&#39;Year&#39;).median() . Completions . Year . 2012 229.5 | . 2013 189.0 | . 2014 203.5 | . 2015 191.0 | . 2016 208.0 | . df.groupby(&#39;Year&#39;).std() . Completions . Year . 2012 1036.433239 | . 2013 1040.474782 | . 2014 1150.355857 | . 2015 1183.371791 | . 2016 1235.952796 | . df.groupby(&#39;Year&#39;).skew() . Completions . Year . 2012 3.682215 | . 2013 3.483705 | . 2014 3.101389 | . 2015 3.142177 | . 2016 3.074736 | . df.groupby(&#39;Year&#39;).var() . Completions . Year . 2012 1.074194e+06 | . 2013 1.082588e+06 | . 2014 1.323319e+06 | . 2015 1.400369e+06 | . 2016 1.527579e+06 | . df.head() . Sector University Year Completions Geography . 0 Private for-profit, 2-year | Pima Medical Institute-Las Vegas | 2016 | 591 | Nevada | . 1 Private for-profit, less-than 2-year | Healthcare Preparatory Institute | 2016 | 28 | Nevada | . 2 Private for-profit, less-than 2-year | Milan Institute-Las Vegas | 2016 | 408 | Nevada | . 3 Private for-profit, less-than 2-year | Utah College of Massage Therapy-Vegas | 2016 | 240 | Nevada | . 4 Public, 4-year or above | Western Nevada College | 2016 | 960 | Nevada | . df.groupby([&#39;Year&#39;, &#39;Sector&#39;]).mean() . Completions . Year Sector . 2012 Private for-profit, 2-year 204.800000 | . Private for-profit, 4-year or above 158.000000 | . Private for-profit, less-than 2-year 189.571429 | . Private not-for-profit, 2-year 332.500000 | . Private not-for-profit, 4-year or above 353.000000 | . Public, 2-year 1170.000000 | . Public, 4-year or above 2068.000000 | . 2013 Private for-profit, 2-year 190.812500 | . Private for-profit, 4-year or above 155.000000 | . Private for-profit, less-than 2-year 183.000000 | . Private not-for-profit, 2-year 235.500000 | . Private not-for-profit, 4-year or above 338.666667 | . Public, 2-year 1633.000000 | . Public, 4-year or above 2136.166667 | . 2014 Private for-profit, 2-year 184.812500 | . Private for-profit, 4-year or above 251.000000 | . Private for-profit, less-than 2-year 166.000000 | . Private not-for-profit, 2-year 224.500000 | . Private not-for-profit, 4-year or above 347.333333 | . Public, 2-year 2286.000000 | . Public, 4-year or above 2527.000000 | . 2015 Private for-profit, 2-year 205.000000 | . Private for-profit, 4-year or above 163.250000 | . Private for-profit, less-than 2-year 203.625000 | . Private not-for-profit, 2-year 212.500000 | . Private not-for-profit, 4-year or above 409.333333 | . Public, 2-year 2355.000000 | . Public, 4-year or above 2676.000000 | . 2016 Private for-profit, 2-year 205.375000 | . Private for-profit, 4-year or above 124.666667 | . Private for-profit, less-than 2-year 194.000000 | . Private not-for-profit, 2-year 161.000000 | . Private not-for-profit, 4-year or above 302.000000 | . Public, 2-year 2431.000000 | . Public, 4-year or above 2779.500000 | . df.groupby(&#39;Year&#39;).describe() . Completions . count mean std min 25% 50% 75% max . Year . 2012 38.0 | 535.078947 | 1036.433239 | 13.0 | 114.25 | 229.5 | 420.50 | 5388.0 | . 2013 40.0 | 526.150000 | 1040.474782 | 0.0 | 98.50 | 189.0 | 413.00 | 5278.0 | . 2014 42.0 | 588.809524 | 1150.355857 | 0.0 | 104.50 | 203.5 | 371.75 | 5093.0 | . 2015 44.0 | 597.250000 | 1183.371791 | 0.0 | 87.75 | 191.0 | 405.75 | 5335.0 | . 2016 43.0 | 609.860465 | 1235.952796 | 0.0 | 90.00 | 208.0 | 414.00 | 5367.0 | . df.groupby(&#39;Year&#39;).describe().transpose() . Year 2012 2013 2014 2015 2016 . Completions count 38.000000 | 40.000000 | 42.000000 | 44.000000 | 43.000000 | . mean 535.078947 | 526.150000 | 588.809524 | 597.250000 | 609.860465 | . std 1036.433239 | 1040.474782 | 1150.355857 | 1183.371791 | 1235.952796 | . min 13.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% 114.250000 | 98.500000 | 104.500000 | 87.750000 | 90.000000 | . 50% 229.500000 | 189.000000 | 203.500000 | 191.000000 | 208.000000 | . 75% 420.500000 | 413.000000 | 371.750000 | 405.750000 | 414.000000 | . max 5388.000000 | 5278.000000 | 5093.000000 | 5335.000000 | 5367.000000 | . Data Input/Output . pwd . &#39;/Users/samtreacy/OneDrive - TietoEVRY/00_Analysis/Jupyter/Tensorflow_Cert/Summaries_to_Study&#39; . ls . 01 Numpy.ipynb Universities.csv example.csv 02 Pandas.ipynb african_econ_crises.csv output.csv Excel_Sample.xlsx bank.csv . df = pd.read_csv(&#39;example.csv&#39;) df . a b c d . 0 0 | 1 | 2 | 3 | . 1 4 | 5 | 6 | 7 | . 2 8 | 9 | 10 | 11 | . 3 12 | 13 | 14 | 15 | . df.to_csv(&#39;example.csv&#39;, index=False) . wiki = pd.read_html(&#39;https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)&#39;) . wiki[7] . Rank Country/Territory GDP(US$million) . 0 NaN | World[19] | 87265226 | . 1 1 | United States | 21439453 | . 2 — | European Union[22][n 1] | 18705132 | . 3 2 | China[n 2] | 14140163 | . 4 3 | Japan | 5154475 | . ... ... | ... | ... | . 189 182 | Palau | 291 | . 190 183 | Marshall Islands | 220 | . 191 184 | Kiribati | 184 | . 192 185 | Nauru | 108 | . 193 186 | Tuvalu | 42 | . 194 rows × 3 columns . tables = pd.read_html(&#39;http://www.fdic.gov/bank/individual/failed/banklist.html&#39;) . tables[0].head() . Bank Name City ST CERT Acquiring Institution Closing Date . 0 The First State Bank | Barboursville | WV | 14361 | MVB Bank, Inc. | April 3, 2020 | . 1 Ericson State Bank | Ericson | NE | 18265 | Farmers and Merchants Bank | February 14, 2020 | . 2 City National Bank of New Jersey | Newark | NJ | 21111 | Industrial Bank | November 1, 2019 | . 3 Resolute Bank | Maumee | OH | 58317 | Buckeye State Bank | October 25, 2019 | . 4 Louisa Community Bank | Louisa | KY | 58112 | Kentucky Farmers Bank Corporation | October 25, 2019 | . Operations . import pandas as pd df_one = pd.DataFrame({&#39;k1&#39;:[&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;], &#39;col1&#39;:[100,200,300,300,400,500], &#39;col2&#39;:[&#39;NY&#39;,&#39;CA&#39;,&#39;WA&#39;,&#39;WA&#39;,&#39;AK&#39;,&#39;NV&#39;]}) . df_one . k1 col1 col2 . 0 A | 100 | NY | . 1 A | 200 | CA | . 2 B | 300 | WA | . 3 B | 300 | WA | . 4 C | 400 | AK | . 5 C | 500 | NV | . df_one[&#39;col2&#39;].unique() . array([&#39;NY&#39;, &#39;CA&#39;, &#39;WA&#39;, &#39;AK&#39;, &#39;NV&#39;], dtype=object) . df_one[&#39;col2&#39;].nunique() . 5 . df_one[&#39;col2&#39;].value_counts() . WA 2 CA 1 AK 1 NY 1 NV 1 Name: col2, dtype: int64 . df_one.drop_duplicates() . k1 col1 col2 . 0 A | 100 | NY | . 1 A | 200 | CA | . 2 B | 300 | WA | . 4 C | 400 | AK | . 5 C | 500 | NV | . df_one[&#39;New Col&#39;] = df_one[&#39;col1&#39;] * 10 df_one . k1 col1 col2 New Col . 0 A | 100 | NY | 1000 | . 1 A | 200 | CA | 2000 | . 2 B | 300 | WA | 3000 | . 3 B | 300 | WA | 3000 | . 4 C | 400 | AK | 4000 | . 5 C | 500 | NV | 5000 | . def grab_first_letter(state): return state[0] . grab_first_letter(&#39;NY&#39;) . &#39;N&#39; . df_one[&#39;col2&#39;].apply(grab_first_letter) . 0 N 1 C 2 W 3 W 4 A 5 N Name: col2, dtype: object . df_one[&#39;first letter&#39;] = df_one[&#39;col2&#39;].apply(grab_first_letter) . df_one . k1 col1 col2 New Col first letter . 0 A | 100 | NY | 1000 | N | . 1 A | 200 | CA | 2000 | C | . 2 B | 300 | WA | 3000 | W | . 3 B | 300 | WA | 3000 | W | . 4 C | 400 | AK | 4000 | A | . 5 C | 500 | NV | 5000 | N | . import pandas as pd df = pd.read_csv(&#39;african_econ_crises.csv&#39;) . df[&#39;country&#39;].nunique() . 13 . df[(df[&#39;country&#39;]==&#39;Kenya&#39;) &amp; (df[&#39;systemic_crisis&#39;]==1)].sort_values(&#39;year&#39;) . case cc3 country year systemic_crisis exch_usd domestic_debt_in_default sovereign_external_debt_default gdp_weighted_default inflation_annual_cpi independence currency_crises inflation_crises banking_crisis . 475 35 | KEN | Kenya | 1985 | 1 | 16.2843 | 0 | 0 | 0.0 | 11.398 | 1 | 0 | 0 | crisis | . 476 35 | KEN | Kenya | 1986 | 1 | 16.0422 | 0 | 0 | 0.0 | 10.284 | 1 | 0 | 0 | crisis | . 477 35 | KEN | Kenya | 1987 | 1 | 16.5149 | 0 | 0 | 0.0 | 13.007 | 1 | 0 | 0 | crisis | . 478 35 | KEN | Kenya | 1988 | 1 | 18.5994 | 0 | 0 | 0.0 | 4.804 | 1 | 0 | 0 | crisis | . 479 35 | KEN | Kenya | 1989 | 1 | 21.6010 | 0 | 0 | 0.0 | 7.617 | 1 | 1 | 0 | no_crisis | . 482 35 | KEN | Kenya | 1992 | 1 | 36.2163 | 0 | 0 | 0.0 | 27.332 | 1 | 1 | 1 | crisis | . 483 35 | KEN | Kenya | 1993 | 1 | 68.1631 | 0 | 0 | 0.0 | 45.979 | 1 | 1 | 1 | crisis | . 484 35 | KEN | Kenya | 1994 | 1 | 44.8389 | 0 | 1 | 0.0 | 28.814 | 1 | 0 | 1 | crisis | . 485 35 | KEN | Kenya | 1995 | 1 | 55.9389 | 0 | 1 | 0.0 | 1.554 | 1 | 0 | 0 | crisis | . 486 35 | KEN | Kenya | 1996 | 1 | 55.0211 | 0 | 1 | 0.0 | 8.862 | 1 | 0 | 0 | no_crisis | . 487 35 | KEN | Kenya | 1997 | 1 | 62.6778 | 0 | 1 | 0.0 | 11.924 | 1 | 0 | 0 | no_crisis | . 488 35 | KEN | Kenya | 1998 | 1 | 61.9056 | 0 | 1 | 0.0 | 6.716 | 1 | 0 | 0 | no_crisis | . 489 35 | KEN | Kenya | 1999 | 1 | 72.9306 | 0 | 0 | 0.0 | 5.753 | 1 | 1 | 0 | no_crisis | .",
            "url": "https://sams101.github.io/DataScience/2020/10/02/Pandas.html",
            "relUrl": "/2020/10/02/Pandas.html",
            "date": " • Oct 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Numpy - Jose Portillo",
            "content": "import numpy as np . my_list = [1,2,3] my_list . [1, 2, 3] . np.array(my_list) . array([1, 2, 3]) . my_matrix = [[1,2,3],[4,5,6],[7,8,9]] my_matrix . [[1, 2, 3], [4, 5, 6], [7, 8, 9]] . np.array(my_matrix) . array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) . np.arange(0,10) . array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) . np.arange(0,11,2) . array([ 0, 2, 4, 6, 8, 10]) . np.zeros((5,5)) . array([[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]) . np.ones(3) . array([1., 1., 1.]) . np.ones((3,4)) . array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) . np.linspace(0,20,5) . array([ 0., 5., 10., 15., 20.]) . np.linspace(0,5,20) . array([0. , 0.26315789, 0.52631579, 0.78947368, 1.05263158, 1.31578947, 1.57894737, 1.84210526, 2.10526316, 2.36842105, 2.63157895, 2.89473684, 3.15789474, 3.42105263, 3.68421053, 3.94736842, 4.21052632, 4.47368421, 4.73684211, 5. ]) . np.linspace(0,5,21) . array([0. , 0.25, 0.5 , 0.75, 1. , 1.25, 1.5 , 1.75, 2. , 2.25, 2.5 , 2.75, 3. , 3.25, 3.5 , 3.75, 4. , 4.25, 4.5 , 4.75, 5. ]) . np.eye(4) . array([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.]]) . np.random.rand(2) . array([0.21178548, 0.18008915]) . np.random.rand(3,4) . array([[0.55366324, 0.67128084, 0.98579352, 0.02325072], [0.07701532, 0.79497617, 0.57776202, 0.26708334], [0.88177627, 0.0227815 , 0.25584316, 0.32664116]]) . np.random.randn(3) . array([ 1.34425056, -1.88190178, -0.04103648]) . np.random.randint(1,100) . 6 . np.random.randint(1,100,10) . array([34, 55, 55, 43, 35, 97, 4, 52, 20, 58]) . np.random.seed(42) . np.random.rand(4) . array([0.37454012, 0.95071431, 0.73199394, 0.59865848]) . arr = np.arange(25) ranarr = np.random.randint(0,50,10) . arr . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]) . ranarr . array([38, 18, 22, 10, 10, 23, 35, 39, 23, 2]) . arr.reshape(5,5) . array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]]) . ranarr . array([38, 18, 22, 10, 10, 23, 35, 39, 23, 2]) . ranarr.max() . 39 . ranarr.min() . 2 . ranarr.argmax() . 7 . ranarr.argmin() . 9 . arr.shape . (25,) . arr.reshape(1,25) . array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]]) . arr.reshape(1,25).shape . (1, 25) . arr.reshape(25,1) . array([[ 0], [ 1], [ 2], [ 3], [ 4], [ 5], [ 6], [ 7], [ 8], [ 9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24]]) . arr.reshape(25,1).shape . (25, 1) . arr.dtype . dtype(&#39;int64&#39;) . arr2 = np.array([1.2, 3.4, 5.6]) arr2.dtype . dtype(&#39;float64&#39;) . import numpy as np . arr = np.arange(0,11) arr . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) . arr[8] . 8 . arr[1:5] . array([1, 2, 3, 4]) . arr[0:4] . array([0, 1, 2, 3]) . arr[0:5] = 100 arr . array([100, 100, 100, 100, 100, 5, 6, 7, 8, 9, 10]) . arr = np.arange(0,11) arr . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) . # important note on slices slice_of_arr = arr[0:6] slice_of_arr . array([0, 1, 2, 3, 4, 5]) . slice_of_arr[:] = 99 slice_of_arr . array([99, 99, 99, 99, 99, 99]) . arr . array([99, 99, 99, 99, 99, 99, 6, 7, 8, 9, 10]) . # To get a copy, need to be explicit arr_copy = arr.copy() arr_copy . array([99, 99, 99, 99, 99, 99, 6, 7, 8, 9, 10]) . Indexing a 2D array (matrices) . The general format is arr_2d[row][col] or arr_2d[row,col]. I recommend using the comma notation for clarity. . arr_2d = np.array(([5,10,15], [20,25,30], [35, 40, 45])) arr_2d . array([[ 5, 10, 15], [20, 25, 30], [35, 40, 45]]) . arr_2d[1] . array([20, 25, 30]) . arr_2d[1][0] . 20 . arr_2d[1,0] . 20 . arr_2d[:2,1:] . array([[10, 15], [25, 30]]) . arr_2d[2] . array([35, 40, 45]) . arr_2d[2,1] . 40 . Conditional Selection . arr = np.arange(1,11) arr . array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) . arr &gt; 4 . array([False, False, False, False, True, True, True, True, True, True]) . bool_arr = arr &gt; 4 bool_arr . array([False, False, False, False, True, True, True, True, True, True]) . arr[bool_arr] . array([ 5, 6, 7, 8, 9, 10]) . arr[arr&gt;2] . array([ 3, 4, 5, 6, 7, 8, 9, 10]) . x = 2 arr[arr&gt;x] . array([ 3, 4, 5, 6, 7, 8, 9, 10]) . NumPy Operations . import numpy as np . arr = np.arange(0,10) arr . array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) . arr + arr . array([ 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]) . arr * arr . array([ 0, 1, 4, 9, 16, 25, 36, 49, 64, 81]) . arr/arr . /Users/samtreacy/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide &#34;&#34;&#34;Entry point for launching an IPython kernel. . array([nan, 1., 1., 1., 1., 1., 1., 1., 1., 1.]) . 1/arr . /Users/samtreacy/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide &#34;&#34;&#34;Entry point for launching an IPython kernel. . array([ inf, 1. , 0.5 , 0.33333333, 0.25 , 0.2 , 0.16666667, 0.14285714, 0.125 , 0.11111111]) . arr ** 4 . array([ 0, 1, 16, 81, 256, 625, 1296, 2401, 4096, 6561]) . Universal Array Functions . np.sqrt(arr) . array([0. , 1. , 1.41421356, 1.73205081, 2. , 2.23606798, 2.44948974, 2.64575131, 2.82842712, 3. ]) . np.exp(arr) . array([1.00000000e+00, 2.71828183e+00, 7.38905610e+00, 2.00855369e+01, 5.45981500e+01, 1.48413159e+02, 4.03428793e+02, 1.09663316e+03, 2.98095799e+03, 8.10308393e+03]) . np.sin(arr) . array([ 0. , 0.84147098, 0.90929743, 0.14112001, -0.7568025 , -0.95892427, -0.2794155 , 0.6569866 , 0.98935825, 0.41211849]) . np.log(arr) . /Users/samtreacy/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log &#34;&#34;&#34;Entry point for launching an IPython kernel. . array([ -inf, 0. , 0.69314718, 1.09861229, 1.38629436, 1.60943791, 1.79175947, 1.94591015, 2.07944154, 2.19722458]) . Summary Statistics on Arrays . arr = np.arange(0,10) . arr.sum() . 45 . arr.mean() . 4.5 . arr.max() . 9 . arr.var() . 8.25 . arr.std() . 2.8722813232690143 . Axis Logic . arr_2d = np.array(([1,2,3,4],[5,6,7,8],[9,10,11,12])) arr_2d . array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) . arr_2d.sum(axis=0) . array([15, 18, 21, 24]) . arr_2d.shape . (3, 4) . arr_2d.sum(axis=1) . array([10, 26, 42]) . NumPy Exercises and Solutions . import numpy as np . np.zeros(10) . array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) . np.ones(10) * 5 . array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.]) . np.arange(10,51,2) . array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50]) . np.arange(9).reshape(3,3) . array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) . np.eye(3) . array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) . np.random.rand(1) . array([0.03663051]) . np.random.randn(25) . array([ 0.97453543, 0.2926023 , -0.92797909, 0.48026505, 1.74186039, -1.69246091, -1.37212144, 0.81768023, -0.13545292, -1.63617008, -1.57488459, -1.43701345, 0.10597854, -0.56858574, -0.31176684, -0.85042466, 0.00568464, -1.58572796, -0.11983444, -0.39465075, -0.89174802, 0.42194063, -2.06712032, -1.94194237, 1.05986301]) . np.arange(1,101).reshape(10,10)/100 . array([[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ], [0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ], [0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 ], [0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 ], [0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 ], [0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6 ], [0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 ], [0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8 ], [0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 ], [0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1. ]]) . np.linspace(0,1,20) . array([0. , 0.05263158, 0.10526316, 0.15789474, 0.21052632, 0.26315789, 0.31578947, 0.36842105, 0.42105263, 0.47368421, 0.52631579, 0.57894737, 0.63157895, 0.68421053, 0.73684211, 0.78947368, 0.84210526, 0.89473684, 0.94736842, 1. ]) . mat = np.arange(1,26).reshape(5,5) mat . array([[ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]) . mat[2:,1:] . array([[12, 13, 14, 15], [17, 18, 19, 20], [22, 23, 24, 25]]) . mat[3,4] . 20 . mat[:3,1:2] . array([[ 2], [ 7], [12]]) . mat[4,:] . array([21, 22, 23, 24, 25]) . mat[3:5,:] . array([[16, 17, 18, 19, 20], [21, 22, 23, 24, 25]]) . mat.sum() . 325 . mat.std() . 7.211102550927978 . mat.sum(axis=0) . array([55, 60, 65, 70, 75]) .",
            "url": "https://sams101.github.io/DataScience/2020/10/02/Numpy.html",
            "relUrl": "/2020/10/02/Numpy.html",
            "date": " • Oct 2, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Matplotlib",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt . x = [0,1,2] y = [100,200,300] . plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x7ffd3f86b4d0&gt;] . # add ; to hide matplotlib output text plt.plot(x,y); . Basic Tools . housing = pd.DataFrame({&#39;rooms&#39;:[1,1,2,2,2,3,3,3,], &#39;price&#39;:[100,120, 190, 200,230,310,330,305]}) housing . rooms price . 0 1 | 100 | . 1 1 | 120 | . 2 2 | 190 | . 3 2 | 200 | . 4 2 | 230 | . 5 3 | 310 | . 6 3 | 330 | . 7 3 | 305 | . plt.scatter(housing[&#39;rooms&#39;], housing[&#39;price&#39;]) . &lt;matplotlib.collections.PathCollection at 0x7ffd3ed8a1d0&gt; . plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x7ffd4031b450&gt;] . plt.plot(x,y, color=&#39;red&#39;) plt.title(&#39;Title&#39;) plt.xlabel(&#39;X Label&#39;) plt.ylabel(&#39;Y Label&#39;) plt.xlim(0,2) plt.ylim(100,300) . (100.0, 300.0) . plt.plot(x,y, color=&#39;red&#39;, marker=&#39;o&#39;, markersize=20, linestyle=&#39;--&#39;) plt.xlim(0,2) plt.ylim(100,300) plt.title(&#39;Title&#39;) plt.xlabel(&#39;X Label&#39;) plt.ylabel(&#39;Y Label&#39;) . Text(0, 0.5, &#39;Y Label&#39;) . Seaborn . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns . ls . 01 Numpy.ipynb Excel_Sample.xlsx example.csv 02 Pandas.ipynb Universities.csv output.csv 03 Matplotlib.ipynb african_econ_crises.csv DATA/ bank.csv . df = pd.read_csv(&#39;DATA/heart.csv&#39;) df.head() . age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal target . 0 63 | 1 | 3 | 145 | 233 | 1 | 0 | 150 | 0 | 2.3 | 0 | 0 | 1 | 1 | . 1 37 | 1 | 2 | 130 | 250 | 0 | 1 | 187 | 0 | 3.5 | 0 | 0 | 2 | 1 | . 2 41 | 0 | 1 | 130 | 204 | 0 | 0 | 172 | 0 | 1.4 | 2 | 0 | 2 | 1 | . 3 56 | 1 | 1 | 120 | 236 | 0 | 1 | 178 | 0 | 0.8 | 2 | 0 | 2 | 1 | . 4 57 | 0 | 0 | 120 | 354 | 0 | 1 | 163 | 1 | 0.6 | 2 | 0 | 2 | 1 | . sns.distplot(df[&#39;age&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd422ff310&gt; . plt.figure(figsize=(12,8)) sns.distplot(df[&#39;age&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd423e3650&gt; . sns.distplot(df[&#39;age&#39;], kde=False); . sns.distplot(df[&#39;age&#39;], kde=False, bins=40, color=&#39;red&#39;) plt.xlim(40,70); . df.head() . age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal target . 0 63 | 1 | 3 | 145 | 233 | 1 | 0 | 150 | 0 | 2.3 | 0 | 0 | 1 | 1 | . 1 37 | 1 | 2 | 130 | 250 | 0 | 1 | 187 | 0 | 3.5 | 0 | 0 | 2 | 1 | . 2 41 | 0 | 1 | 130 | 204 | 0 | 0 | 172 | 0 | 1.4 | 2 | 0 | 2 | 1 | . 3 56 | 1 | 1 | 120 | 236 | 0 | 1 | 178 | 0 | 0.8 | 2 | 0 | 2 | 1 | . 4 57 | 0 | 0 | 120 | 354 | 0 | 1 | 163 | 1 | 0.6 | 2 | 0 | 2 | 1 | . sns.countplot(x=&#39;sex&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd4324c6d0&gt; . sns.countplot(df[&#39;sex&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd43428dd0&gt; . sns.countplot(x=&#39;target&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd4350cf50&gt; . sns.countplot(x=&#39;cp&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd435e7910&gt; . sns.countplot(x=&#39;cp&#39;, hue=&#39;sex&#39;, data=df); . sns.countplot(x=&#39;cp&#39;, palette=&#39;terrain&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd42cf9910&gt; . sns.boxplot(x=&#39;sex&#39;, y=&#39;age&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd42a93a10&gt; . sns.boxplot(x=&#39;sex&#39;, y=&#39;age&#39;, hue=&#39;sex&#39;, data=df); . Scatter Plots . sns.scatterplot(x=&#39;chol&#39;, y=&#39;trestbps&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd42e99e10&gt; . sns.scatterplot(x=&#39;chol&#39;, y=&#39;trestbps&#39;, hue=&#39;sex&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd43950c10&gt; . sns.scatterplot(x=&#39;chol&#39;, y=&#39;trestbps&#39;, hue=&#39;sex&#39;, palette=&#39;Dark2&#39;,data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd42e3bd10&gt; . sns.scatterplot(x=&#39;chol&#39;, y=&#39;trestbps&#39;, size=&#39;age&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ffd42e549d0&gt; . iris = pd.read_csv(&#39;DATA/iris.csv&#39;) . iris.head() . sepal_length sepal_width petal_length petal_width species . 0 5.1 | 3.5 | 1.4 | 0.2 | setosa | . 1 4.9 | 3.0 | 1.4 | 0.2 | setosa | . 2 4.7 | 3.2 | 1.3 | 0.2 | setosa | . 3 4.6 | 3.1 | 1.5 | 0.2 | setosa | . 4 5.0 | 3.6 | 1.4 | 0.2 | setosa | . sns.pairplot(iris); . sns.pairplot(iris, hue=&#39;species&#39;); . cd OneDrive - TietoEVRY/ . /Users/samtreacy/OneDrive - TietoEVRY . cd 00 Analysis/ . /Users/samtreacy/OneDrive - TietoEVRY/00 Analysis . diamonds = pd.read_csv(&#39;DATA/diamonds.csv&#39;) . diamonds[&#39;cut&#39;].unique() . array([&#39;Ideal&#39;, &#39;Premium&#39;, &#39;Good&#39;, &#39;Very Good&#39;, &#39;Fair&#39;], dtype=object) . cut_order = list(diamonds[&#39;cut&#39;].unique()) . cut_order . [&#39;Ideal&#39;, &#39;Premium&#39;, &#39;Good&#39;, &#39;Very Good&#39;, &#39;Fair&#39;] . plt.figure(figsize=(12,8)) sns.boxplot(x=&#39;cut&#39;, y=&#39;price&#39;, data=diamonds, order=cut_order,palette=&#39;cool&#39; ); .",
            "url": "https://sams101.github.io/DataScience/2020/10/02/Matplotlib_Seaborn.html",
            "relUrl": "/2020/10/02/Matplotlib_Seaborn.html",
            "date": " • Oct 2, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sams101.github.io/DataScience/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your page/pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sams101.github.io/DataScience/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sams101.github.io/DataScience/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}